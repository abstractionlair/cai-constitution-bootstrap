# Task: Fix Data Leakage Between Train/Eval

## Task: Create disjoint train/eval data splits
Priority: P0 (CRITICAL - invalidates results)
Estimated Time: 1.0 hours
Created: 2024-12-28 13:00
Created By: Claude (Project)

## Objective
Ensure training and evaluation data are completely disjoint to prevent memorization/leakage.

## Success Criteria
- [ ] Separate content pools for train vs eval
- [ ] Assertion that verifies no overlap between sets
- [ ] Clear documentation of split methodology
- [ ] Reproducible split (same seed = same split)

## Files to Modify
- `scripts/utils/data_formatter.py` - Split content pools into train/eval
- `scripts/generate_stage1_data.py` - Use only train pool for generation
- `scripts/evaluate_stage1.py` - Use only eval pool for evaluation
- Add `scripts/utils/data_splitter.py` - Handle split logic

## Dependencies
- Precision fix should be done first (for cleaner testing)

## Implementation Notes
Current issue: Same QA questions, completions, etc. used for both training and evaluation.

Suggested approach:
1. In data_formatter.py, create train/eval splits:
```python
def split_content_pools(self, eval_ratio=0.2, seed=42):
    """Split all content pools into train/eval sets"""
    np.random.seed(seed)
    
    # Split QA items
    qa_items = list(self.qa_content.items())
    np.random.shuffle(qa_items)
    split_idx = int(len(qa_items) * (1 - eval_ratio))
    self.qa_train = dict(qa_items[:split_idx])
    self.qa_eval = dict(qa_items[split_idx:])
    
    # Repeat for other content types...
    
    # Add assertion
    assert len(set(self.qa_train.keys()) & set(self.qa_eval.keys())) == 0
```

2. Add flag to generate functions:
```python
def generate_qa_instruction(self, is_eval=False):
    pool = self.qa_eval if is_eval else self.qa_train
    # ... rest of generation
```

## Test Plan
1. Generate train and eval sets
2. Run overlap check - should find 0 overlaps
3. Verify split is deterministic (same seed = same split)
4. Check that both pools have sufficient examples

---

## Status Updates
- [2024-12-28 15:20] Started implementation - Claude Code
- [2024-12-28 15:20] Refactored Stage1DataGenerator to use separate content pools
- [2024-12-28 15:25] Added automatic train/eval splitting with assertions
- [2024-12-28 15:25] Updated all generate methods to support is_eval parameter
- [2024-12-28 15:30] ✅ COMPLETED - All methods now use separate train/eval pools
- [2024-12-28 15:30] ✅ All success criteria met:
  - ✅ Separate content pools for train vs eval (80/20 split)
  - ✅ Assertions verify no overlap between sets (0 overlaps found)
  - ✅ Clear documentation of split methodology (deterministic with seed)
  - ✅ Reproducible split (same seed = same split)
- [2024-12-28 15:30] ✅ Tested successfully - 0 data leakage detected
