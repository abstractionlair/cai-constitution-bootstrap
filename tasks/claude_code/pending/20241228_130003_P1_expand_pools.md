# Task: Expand Data Pools Moderately

## Task: Increase content pools for better training diversity
Priority: P1 (Important but not blocking)
Estimated Time: 1.0 hours
Created: 2024-12-28 13:00
Created By: Claude (Project)

## Objective
Expand the content pools to have sufficient unique examples for 500-1000 training samples.

## Success Criteria
- [ ] QA pool: At least 100 unique questions (currently ~30)
- [ ] Completion pool: At least 80 unique partials (currently ~20)
- [ ] Response pool: At least 80 unique inputs (currently ~20)
- [ ] No duplicate content within each pool

## Files to Modify
- `scripts/utils/data_formatter.py` - Expand all content dictionaries

## Dependencies
- Should be done AFTER data leakage fix (so we split the expanded pools correctly)

## Implementation Notes
This is about quality, not critical for the automation experiment.

Current sizes are too small for 500-1000 training examples. Aim for:
- Enough variety that each example is relatively unique
- But don't need to go overboard (this isn't the core experiment)

Can generate additional content programmatically:
```python
# Example: Generate more QA items
def expand_qa_pool(self):
    base_topics = ['science', 'history', 'geography', 'technology', 'culture']
    question_types = ['what', 'when', 'where', 'who', 'why', 'how']
    
    for topic in base_topics:
        for q_type in question_types:
            # Generate variations...
```

## Test Plan
1. Count unique items in each pool
2. Verify no duplicates
3. Check that generation still works with expanded pools
4. Ensure train/eval split still works

---

## Status Updates
[Claude Code adds updates here]
